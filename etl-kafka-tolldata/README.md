# Hands-on Lab: Build a Streaming ETL Pipeline using Kafka

> Apache Airflow Final Assignment of Course 8 of 13 in the [IBM Data Engineering Specialization](https://www.coursera.org/specializations/ibm-data-engineer)

## Scenario

You are a data engineer at a data analytics consulting company. You have been assigned to a project that aims to de-congest the national highways by analyzing the road traffic data from different toll plazas. As a vehicle passes a toll plaza, the vehicleâ€™s data like `vehicle_id`,`vehicle_type`, `toll_plaza_id` and timestamp are streamed to Kafka. Your job is to create a data pipe line that collects the streaming data and loads it into a database.

## Objectives

In this assignment you will create a streaming data pipe by performing these steps:

- Start a MySQL Database server.
- Create a table to hold the toll data.
- Start the Kafka server.
- Install the Kafka python driver.
- Install the MySQL python driver.
- Create a topic named toll in kafka.
- Download streaming data generator program.
- Customize the generator program to steam to toll topic.
- Download and customise streaming data consumer.
- Customize the consumer program to write into a MySQL database table.
- Verify that streamed data is being collected in the database table.

## Steps to run the code

### Step 1: Download Kafka inside the directory

```bash
wget https://archive.apache.org/dist/kafka/2.8.0/kafka_2.12-2.8.0.tgz
```

### Step 2: Extract the downloaded file

```bash
tar -xzf kafka_2.12-2.8.0.tgz
```

### Step 3: Connect to the mysql server

```bash
mysql -u root -p
```

### Step 4: Create a database named `tolldata`

```bash
create database tolldata;
```

### Step 5: Create a table named `livetolldata` with the schema to store the data generated by the traffic simulator.

```bash
use tolldata;

create table livetolldata(timestamp datetime,vehicle_id int,vehicle_type char(15),toll_plaza_id smallint);
```

### Step 6: Install the python module `kafka-python`

```bash
pip install kafka-python
```

### Step 7: Install the python module `mysql-connector-python`

```bash
pip install mysql-connector-python
```

### Step 8: Start zookeeper server.

```bash
cd kafka_2.12-2.8.0
bin/zookeeper-server-start.sh config/zookeeper.properties
```

### Step 9: Start kafka server.

```bash
cd kafka_2.12-2.8.0
bin/kafka-server-start.sh config/server.properties
```

### Step 10: Create a topic named `toll` in kafka.

```bash
cd kafka_2.12-2.8.0
bin/kafka-topics.sh --create --topic toll --bootstrap-server localhost:9092
```

### Step 11: Run the Toll Traffic Simulator.

```bash
python toll_traffic_simulator.py
```

### Step 12: Run `streaming_data_reader.py`

```bash
python streaming_data_reader.py
```

> Make sure to replace the `DATABASE`, `USERNAME`, and `PASSWORD` variables in `streaming_data_reader.py` with the correct values for your MySQL database.

### Step 13: Verify that the data is being streamed to the database.

If you have done all the steps till here correctly, the streaming toll data would get stored in the table livetolldata.

List the top 10 rows in the table livetolldata.
